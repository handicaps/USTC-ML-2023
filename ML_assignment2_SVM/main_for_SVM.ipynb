{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In real-world scenarios, learning how the data was generated is impractical. Do not rely on this function while doing research.\n",
    "def generate_data(dim, num):\n",
    "    x = np.random.normal(0, 10, [num, dim])\n",
    "    coef = np.random.uniform(-1, 1, [dim, 1])\n",
    "    pred = np.dot(x, coef)\n",
    "    pred_n = (pred - np.mean(pred)) / np.sqrt(np.var(pred))\n",
    "    label = np.sign(pred_n)\n",
    "    mislabel_value = np.random.uniform(0, 1, num)\n",
    "    mislabel = 0\n",
    "    for i in range(num):\n",
    "        if np.abs(pred_n[i]) < 1 and mislabel_value[i] > 0.9 + 0.1 * np.abs(pred_n[i]):\n",
    "            label[i] *= -1\n",
    "            mislabel += 1\n",
    "    return x, label, mislabel/num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write your model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the overall structure is acceptable but not recommended\n",
    "class SVM1:\n",
    "    def __init__(self, dim,C=1.0,tol=1e-4,max_iter=1000):\n",
    "        \"\"\"\n",
    "        Adding other parameters is acceptable but not necessary.\n",
    "        \"\"\"\n",
    "        self.dim=dim\n",
    "        self.C=C\n",
    "        self.tol=tol\n",
    "        self.max_iter=max_iter\n",
    "        self.alpha=None\n",
    "        self.bias=None\n",
    "\n",
    "    def _compute_weight(self,alpha,X,y):\n",
    "        return np.sum(alpha[i]*y[i]*x[i] for i in range(len(alpha)))\n",
    "    \n",
    "    def _compute_bias(self,alpha,X,y,w):\n",
    "        #对应支持向量的位置\n",
    "        support_indice=np.where((alpha>1e-5))[0]\n",
    "        return np.mean(y[support_indice]-np.dot(X[support_indice],w))\n",
    "\n",
    "    \n",
    "    def _duiou_function(self,alpha):\n",
    "        #目标函数\n",
    "        return 0.5* np.sum(alpha **2)-np.sum(alpha)\n",
    "\n",
    "    def _constraint(self,alpha,y):\n",
    "        #约束函数\n",
    "        return np.sum(alpha*self.y)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the coefficients via your method1\n",
    "        \"\"\"\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        tol=self.tol\n",
    "        C=self.C\n",
    "        num=X.shape[0]\n",
    "\n",
    "        alpha=np.zeros(num)\n",
    "        bias=0\n",
    "        iter_times=0\n",
    "\n",
    "        while iter_times< self.max_iter:\n",
    "            alpha_prev=np.copy(alpha)\n",
    "\n",
    "            for i in range(num):\n",
    "                #E_i表示f(x)\n",
    "                E_i=np.dot(alpha*y,(np.dot(X,X[i].T)))+bias-y[i]\n",
    "                if(y[i]*E_i<-self.tol and alpha[i]<self.C) or (y[i]*E_i>self.tol and alpha[i]>0):\n",
    "                    j=np.random.choice(num)\n",
    "                    while j==i:\n",
    "                        j=np.random.choice(num)\n",
    "                    \n",
    "                    E_j=np.dot(alpha*y,(np.dot(X,X[j].T)))+bias-y[j]\n",
    "                    alpha_i_prev,alpha_j_prev=alpha[i],alpha[j]\n",
    "\n",
    "                    if y[i]!=y[j]:\n",
    "                        L=max(0,alpha[j]-alpha[i])\n",
    "                        H=min(C,C+alpha[j]-alpha[i])\n",
    "                    else:\n",
    "                        L=max(0,alpha[i]+alpha[j]-C)\n",
    "                        H=min(C,alpha[i]+alpha[j])\n",
    "                \n",
    "                    if L==H:\n",
    "                        continue\n",
    "\n",
    "                    eta= 2*np.dot(X[i],X[j].T)-np.dot(X[i],X[i].T)-np.dot(X[j],X[j].T)\n",
    "                    if eta>=0:\n",
    "                        continue\n",
    "\n",
    "                    alpha[j]=alpha[j]-(y[j]*(E_i-E_j))/eta\n",
    "                    alpha[j]=max(L,min(H,alpha[j]))\n",
    "\n",
    "                    if abs(alpha_j_prev-alpha[j])<1e-5:\n",
    "                        continue\n",
    "\n",
    "                    alpha[i]=alpha[i]+y[i]*y[j]*(alpha_j_prev-alpha[j])\n",
    "\n",
    "                    b1=bias-E_i + y[i]*(alpha_i_prev-alpha[i])*np.dot(X[i],X[i].T)-y[j]*(alpha[j]-alpha_j_prev)*np.dot(X[i],X[j].T)\n",
    "                    b2=bias-E_j + y[i]*(alpha_i_prev-alpha[i])*np.dot(X[i],X[j].T)-y[j]*(alpha[j]-alpha_j_prev)*np.dot(X[j],X[i].T)\n",
    "\n",
    "                    if 0<alpha[i]<C:\n",
    "                        bias=b1\n",
    "                    if 0<alpha[i]<C:\n",
    "                        bias=b2\n",
    "\n",
    "                    else:\n",
    "                        bias=(b1+b2)/2\n",
    "                \n",
    "            iter_times+=1\n",
    "\n",
    "            if np.linalg.norm(alpha-alpha_prev)<tol:\n",
    "                break\n",
    "\n",
    "            self.alpha=alpha\n",
    "            w=self._compute_weight(alpha,X,y)\n",
    "            self.bias=self._compute_bias(alpha,X,y,w)\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Generate prediction probabilities on a new\n",
    "        collection of data points by your model.\n",
    "        \"\"\"\n",
    "        return np.sign(np.dot(X,self._compute_weight(self.alpha,self.X,self.y))+self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "x, y, mislabel_rate = generate_data(25, 10000)\n",
    "\n",
    "# Split data (80% training, 20% testing)\n",
    "data_nums = y.shape[0]\n",
    "y = y.reshape(data_nums)\n",
    "split_idx = int(0.8 * len(x))\n",
    "X_train, y_train = x[:split_idx], y[:split_idx]\n",
    "X_test, y_test = x[split_idx:], y[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CindyWu\\AppData\\Local\\Temp\\ipykernel_29524\\1259433648.py:15: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(alpha[i]*y[i]*x[i] for i in range(len(alpha)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM1 accuracy on X_train: 0.882125\n",
      "SVM1 accuracy on X_test: 0.867\n",
      "SVM1 time for fitting and predict:45.823442s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model1 = SVM1(dim=20, C=1.0, tol=1e-3, max_iter=100)\n",
    "svmtime1_a=time.time()\n",
    "model1.fit(X_train, y_train)\n",
    "pred1 = model1.predict(X_test)\n",
    "svmtime1_b=time.time()\n",
    "print(\"SVM1 accuracy on X_train:\", np.mean(model1.predict(X_train) == y_train))\n",
    "print(\"SVM1 accuracy on X_test:\", np.mean(model1.predict(X_test) == y_test))\n",
    "print('SVM1 time for fitting and predict:%fs' % (svmtime1_b - svmtime1_a)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SVM2:\n",
    "    def __init__(self, dim, learning_rate=0.00001, epochs=1000):\n",
    "        \"\"\"\n",
    "        Adding other parameters is acceptable but not necessary.\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.zeros(dim)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the coefficients via your method2\n",
    "        \"\"\"\n",
    "        for epoch in range(self.epochs):\n",
    "            # Calculate predictions and hinge loss\n",
    "            predictions = np.dot(X, self.weights)\n",
    "            hinge_loss = np.maximum(0, 1 - y * predictions)\n",
    "\n",
    "            # Update weights with gradient descent\n",
    "            gradient = -np.dot(X.T, y * (hinge_loss > 0))\n",
    "            self.weights -= self.learning_rate * gradient\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        A same predict function with SVM1 is acceptable.\n",
    "        \"\"\"\n",
    "        predictions = np.dot(X, self.weights)\n",
    "        return np.sign(predictions)#.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct and train your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "# X_data, y_data, mislabel = generate_data() \n",
    "\n",
    "# split data\n",
    "\n",
    "\n",
    "# constrcut model and train (remember to record your time consumption)\n",
    "# model1 = SVM1() \n",
    "# model1.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) \n",
    "x, y, mislabel_rate = generate_data(25, 10000)\n",
    "\n",
    "data_nums = y.shape[0]\n",
    "y = y.reshape(data_nums)\n",
    "split_idx = int(0.8 * len(x))\n",
    "X_train, y_train = x[:split_idx], y[:split_idx]\n",
    "X_test, y_test = x[split_idx:], y[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict and compare your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "# pred = model1.predict()\n",
    "\n",
    "# compare with generated label\n",
    "\n",
    "# compare each method\n",
    "\n",
    "# (Optional) compare with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CindyWu\\AppData\\Local\\Temp\\ipykernel_29524\\1259433648.py:15: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(alpha[i]*y[i]*x[i] for i in range(len(alpha)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM1 accuracy on X_train: 0.90775\n",
      "SVM1 accuracy on X_test: 0.908\n",
      "SVM1 time for fitting:31.383779s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model1 = SVM1(dim=25, C=1.0, tol=1e-4, max_iter=50)\n",
    "svmtime1_a=time.time()\n",
    "model1.fit(X_train, y_train)\n",
    "svmtime1_b=time.time()\n",
    "pred1 = model1.predict(X_test)\n",
    "print(\"SVM1 accuracy on X_train:\", np.mean(model1.predict(X_train) == y_train))\n",
    "print(\"SVM1 accuracy on X_test:\", np.mean(model1.predict(X_test) == y_test))\n",
    "print('SVM1 time for fitting:%fs' % (svmtime1_b - svmtime1_a)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0353"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mislabel_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM2 accuracy on X_train: 0.959125\n",
      "SVM2 accuracy on X_test: 0.9655\n",
      "SVM2 time for fitting and predict: 0.150336s\n"
     ]
    }
   ],
   "source": [
    "model2 = SVM2(dim=25, learning_rate=1e-5, epochs=2000)\n",
    "svmtime2_a=time.time()\n",
    "model2.fit(X_train, y_train)\n",
    "svmtime2_b=time.time()\n",
    "pred2 = model2.predict(X_test)\n",
    "print(\"SVM2 accuracy on X_train:\", np.mean(model2.predict(X_train) == y_train))\n",
    "print(\"SVM2 accuracy on X_test:\", np.mean(model2.predict(X_test) == y_test))\n",
    "print('SVM2 time for fitting: %fs' % (svmtime2_b - svmtime2_a)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn accuracy on X_train: 0.971\n",
      "sklearn accuracy on X_test: 0.9465\n",
      "sklearn time 0.903238s\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "standard = svm.SVC()  \n",
    "svmtime_sklearn_a=time.time()\n",
    "standard.fit(X_train,y_train)\n",
    "svmtime_sklearn_b = time.time()\n",
    "print(\"sklearn accuracy on X_train:\",standard.score(X_train, y_train))\n",
    "print(\"sklearn accuracy on X_test:\",standard.score(X_test, y_test))   \n",
    "print('sklearn time %fs' % (svmtime_sklearn_b - svmtime_sklearn_a)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
